// @ts-nocheck
// Auto-generated by tauri-specta. DO NOT EDIT.

// This file was generated by [tauri-specta](https://github.com/oscartbeaumont/tauri-specta). Do not edit this file manually.

/** user-defined commands **/


export const commands = {
/**
 * Get the application version with -local suffix when running in debug mode
 */
async getAppVersion() : Promise<string> {
    return await TAURI_INVOKE("get_app_version");
},
async checkAccessibilityPermission() : Promise<boolean> {
    return await TAURI_INVOKE("check_accessibility_permission");
},
async requestAccessibilityPermission() : Promise<void> {
    await TAURI_INVOKE("request_accessibility_permission");
},
/**
 * Check microphone permission status
 * Returns: "authorized", "denied", "restricted", or "not_determined"
 */
async checkMicrophonePermission() : Promise<string> {
    return await TAURI_INVOKE("check_microphone_permission");
},
/**
 * Request microphone permission (triggers native permission dialog)
 */
async requestMicrophonePermission() : Promise<boolean> {
    return await TAURI_INVOKE("request_microphone_permission");
},
/**
 * Open System Settings to the Microphone privacy pane
 */
async openMicrophoneSettings() : Promise<void> {
    await TAURI_INVOKE("open_microphone_settings");
},
/**
 * Load the entire app configuration
 */
async loadAppConfig() : Promise<Result<AppConfig, string>> {
    try {
    return { status: "ok", data: await TAURI_INVOKE("load_app_config") };
} catch (e) {
    if(e instanceof Error) throw e;
    else return { status: "error", error: e  as any };
}
},
/**
 * Save app configuration (general-purpose command that can update multiple fields)
 */
async saveAppConfig(activeProvider: string | null, recordingTrigger: RecordingTrigger | null, postProcessEnabled: boolean | null, postProcessModel: string | null, postProcessPrompt: string | null, minSpeechDurationMs: number | null) : Promise<Result<null, string>> {
    try {
    return { status: "ok", data: await TAURI_INVOKE("save_app_config", { activeProvider, recordingTrigger, postProcessEnabled, postProcessModel, postProcessPrompt, minSpeechDurationMs }) };
} catch (e) {
    if(e instanceof Error) throw e;
    else return { status: "error", error: e  as any };
}
},
/**
 * Get the currently active provider
 */
async getCurrentProvider() : Promise<Result<Provider | null, string>> {
    try {
    return { status: "ok", data: await TAURI_INVOKE("get_current_provider") };
} catch (e) {
    if(e instanceof Error) throw e;
    else return { status: "error", error: e  as any };
}
},
/**
 * Set the currently active provider
 */
async setCurrentProvider(provider: string) : Promise<Result<null, string>> {
    try {
    return { status: "ok", data: await TAURI_INVOKE("set_current_provider", { provider }) };
} catch (e) {
    if(e instanceof Error) throw e;
    else return { status: "error", error: e  as any };
}
},
/**
 * Clear the currently active provider (set to None)
 */
async clearCurrentProvider() : Promise<Result<null, string>> {
    try {
    return { status: "ok", data: await TAURI_INVOKE("clear_current_provider") };
} catch (e) {
    if(e instanceof Error) throw e;
    else return { status: "error", error: e  as any };
}
},
async loadOpenaiConfig() : Promise<Result<OpenAIConfigStatus | null, string>> {
    try {
    return { status: "ok", data: await TAURI_INVOKE("load_openai_config") };
} catch (e) {
    if(e instanceof Error) throw e;
    else return { status: "error", error: e  as any };
}
},
async saveOpenaiConfig(apiKey: string) : Promise<Result<null, string>> {
    try {
    return { status: "ok", data: await TAURI_INVOKE("save_openai_config", { apiKey }) };
} catch (e) {
    if(e instanceof Error) throw e;
    else return { status: "error", error: e  as any };
}
},
async deleteOpenaiConfig() : Promise<Result<null, string>> {
    try {
    return { status: "ok", data: await TAURI_INVOKE("delete_openai_config") };
} catch (e) {
    if(e instanceof Error) throw e;
    else return { status: "error", error: e  as any };
}
},
async testOpenaiConfig(apiKey: string) : Promise<Result<boolean, string>> {
    try {
    return { status: "ok", data: await TAURI_INVOKE("test_openai_config", { apiKey }) };
} catch (e) {
    if(e instanceof Error) throw e;
    else return { status: "error", error: e  as any };
}
},
async loadAzureOpenaiConfig() : Promise<Result<AzureOpenAIConfigStatus | null, string>> {
    try {
    return { status: "ok", data: await TAURI_INVOKE("load_azure_openai_config") };
} catch (e) {
    if(e instanceof Error) throw e;
    else return { status: "error", error: e  as any };
}
},
async saveAzureOpenaiConfig(apiKey: string, endpoint: string) : Promise<Result<null, string>> {
    try {
    return { status: "ok", data: await TAURI_INVOKE("save_azure_openai_config", { apiKey, endpoint }) };
} catch (e) {
    if(e instanceof Error) throw e;
    else return { status: "error", error: e  as any };
}
},
async deleteAzureOpenaiConfig() : Promise<Result<null, string>> {
    try {
    return { status: "ok", data: await TAURI_INVOKE("delete_azure_openai_config") };
} catch (e) {
    if(e instanceof Error) throw e;
    else return { status: "error", error: e  as any };
}
},
async testAzureOpenaiConfig(apiKey: string, endpoint: string) : Promise<Result<boolean, string>> {
    try {
    return { status: "ok", data: await TAURI_INVOKE("test_azure_openai_config", { apiKey, endpoint }) };
} catch (e) {
    if(e instanceof Error) throw e;
    else return { status: "error", error: e  as any };
}
},
/**
 * Get list of all available models with their current status
 */
async getAvailableModels() : Promise<ModelInfo[]> {
    return await TAURI_INVOKE("get_available_models");
},
/**
 * Start downloading a model
 */
async downloadModel(modelName: string) : Promise<Result<null, string>> {
    try {
    return { status: "ok", data: await TAURI_INVOKE("download_model", { modelName }) };
} catch (e) {
    if(e instanceof Error) throw e;
    else return { status: "error", error: e  as any };
}
},
/**
 * Cancel an ongoing model download
 */
async cancelModelDownload(modelName: string) : Promise<Result<null, string>> {
    try {
    return { status: "ok", data: await TAURI_INVOKE("cancel_model_download", { modelName }) };
} catch (e) {
    if(e instanceof Error) throw e;
    else return { status: "error", error: e  as any };
}
},
/**
 * Delete a downloaded model
 */
async deleteModel(modelName: string) : Promise<Result<null, string>> {
    try {
    return { status: "ok", data: await TAURI_INVOKE("delete_model", { modelName }) };
} catch (e) {
    if(e instanceof Error) throw e;
    else return { status: "error", error: e  as any };
}
},
/**
 * Load a model into memory for transcription
 */
async loadModel(modelName: string) : Promise<Result<null, string>> {
    try {
    return { status: "ok", data: await TAURI_INVOKE("load_model", { modelName }) };
} catch (e) {
    if(e instanceof Error) throw e;
    else return { status: "error", error: e  as any };
}
},
/**
 * Unload the currently loaded model (frees memory)
 */
async unloadModel() : Promise<void> {
    await TAURI_INVOKE("unload_model");
},
/**
 * Get the name of the currently loaded model
 */
async getLoadedModel() : Promise<string | null> {
    return await TAURI_INVOKE("get_loaded_model");
},
/**
 * Load local model configuration
 */
async loadLocalModelConfig() : Promise<Result<LocalModelConfig | null, string>> {
    try {
    return { status: "ok", data: await TAURI_INVOKE("load_local_model_config") };
} catch (e) {
    if(e instanceof Error) throw e;
    else return { status: "error", error: e  as any };
}
},
/**
 * Save local model configuration (selected model)
 */
async saveLocalModelConfig(modelName: string) : Promise<Result<null, string>> {
    try {
    return { status: "ok", data: await TAURI_INVOKE("save_local_model_config", { modelName }) };
} catch (e) {
    if(e instanceof Error) throw e;
    else return { status: "error", error: e  as any };
}
},
/**
 * Delete local model configuration
 */
async deleteLocalModelConfig() : Promise<Result<null, string>> {
    try {
    return { status: "ok", data: await TAURI_INVOKE("delete_local_model_config") };
} catch (e) {
    if(e instanceof Error) throw e;
    else return { status: "error", error: e  as any };
}
},
async stopRecording() : Promise<Result<null, string>> {
    try {
    return { status: "ok", data: await TAURI_INVOKE("stop_recording") };
} catch (e) {
    if(e instanceof Error) throw e;
    else return { status: "error", error: e  as any };
}
},
async cancelRecording() : Promise<Result<null, string>> {
    try {
    return { status: "ok", data: await TAURI_INVOKE("cancel_recording") };
} catch (e) {
    if(e instanceof Error) throw e;
    else return { status: "error", error: e  as any };
}
},
async retryTranscription() : Promise<Result<null, string>> {
    try {
    return { status: "ok", data: await TAURI_INVOKE("retry_transcription") };
} catch (e) {
    if(e instanceof Error) throw e;
    else return { status: "error", error: e  as any };
}
},
async dismissError() : Promise<Result<null, string>> {
    try {
    return { status: "ok", data: await TAURI_INVOKE("dismiss_error") };
} catch (e) {
    if(e instanceof Error) throw e;
    else return { status: "error", error: e  as any };
}
},
async resizePopupForError() : Promise<Result<null, string>> {
    try {
    return { status: "ok", data: await TAURI_INVOKE("resize_popup_for_error") };
} catch (e) {
    if(e instanceof Error) throw e;
    else return { status: "error", error: e  as any };
}
},
async registerAudioLevelChannel(channel: TAURI_CHANNEL<number>) : Promise<Result<null, string>> {
    try {
    return { status: "ok", data: await TAURI_INVOKE("register_audio_level_channel", { channel }) };
} catch (e) {
    if(e instanceof Error) throw e;
    else return { status: "error", error: e  as any };
}
},
async restartApp() : Promise<void> {
    await TAURI_INVOKE("restart_app");
},
async loadOnboardingConfig() : Promise<Result<OnboardingConfig, string>> {
    try {
    return { status: "ok", data: await TAURI_INVOKE("load_onboarding_config") };
} catch (e) {
    if(e instanceof Error) throw e;
    else return { status: "error", error: e  as any };
}
},
async saveOnboardingStep(step: OnboardingStep) : Promise<Result<null, string>> {
    try {
    return { status: "ok", data: await TAURI_INVOKE("save_onboarding_step", { step }) };
} catch (e) {
    if(e instanceof Error) throw e;
    else return { status: "error", error: e  as any };
}
},
async finishOnboarding() : Promise<Result<null, string>> {
    try {
    return { status: "ok", data: await TAURI_INVOKE("finish_onboarding") };
} catch (e) {
    if(e instanceof Error) throw e;
    else return { status: "error", error: e  as any };
}
},
async skipOnboarding() : Promise<Result<null, string>> {
    try {
    return { status: "ok", data: await TAURI_INVOKE("skip_onboarding") };
} catch (e) {
    if(e instanceof Error) throw e;
    else return { status: "error", error: e  as any };
}
},
async setPendingRestart(pending: boolean) : Promise<Result<null, string>> {
    try {
    return { status: "ok", data: await TAURI_INVOKE("set_pending_restart", { pending }) };
} catch (e) {
    if(e instanceof Error) throw e;
    else return { status: "error", error: e  as any };
}
},
async restartOnboarding() : Promise<Result<null, string>> {
    try {
    return { status: "ok", data: await TAURI_INVOKE("restart_onboarding") };
} catch (e) {
    if(e instanceof Error) throw e;
    else return { status: "error", error: e  as any };
}
},
async loadShortcutsConfig() : Promise<Result<ShortcutsConfig, string>> {
    try {
    return { status: "ok", data: await TAURI_INVOKE("load_shortcuts_config") };
} catch (e) {
    if(e instanceof Error) throw e;
    else return { status: "error", error: e  as any };
}
},
async saveShortcutsConfig(config: ShortcutsConfig) : Promise<Result<null, string>> {
    try {
    return { status: "ok", data: await TAURI_INVOKE("save_shortcuts_config", { config }) };
} catch (e) {
    if(e instanceof Error) throw e;
    else return { status: "error", error: e  as any };
}
},
async resetShortcutsConfig() : Promise<Result<ShortcutsConfig, string>> {
    try {
    return { status: "ok", data: await TAURI_INVOKE("reset_shortcuts_config") };
} catch (e) {
    if(e instanceof Error) throw e;
    else return { status: "error", error: e  as any };
}
},
async startKeyCapture() : Promise<Result<null, string>> {
    try {
    return { status: "ok", data: await TAURI_INVOKE("start_key_capture") };
} catch (e) {
    if(e instanceof Error) throw e;
    else return { status: "error", error: e  as any };
}
},
async stopKeyCapture() : Promise<Result<null, string>> {
    try {
    return { status: "ok", data: await TAURI_INVOKE("stop_key_capture") };
} catch (e) {
    if(e instanceof Error) throw e;
    else return { status: "error", error: e  as any };
}
},
/**
 * Enable autostart on system boot
 */
async enableAutostart() : Promise<Result<null, string>> {
    try {
    return { status: "ok", data: await TAURI_INVOKE("enable_autostart") };
} catch (e) {
    if(e instanceof Error) throw e;
    else return { status: "error", error: e  as any };
}
},
/**
 * Disable autostart on system boot
 */
async disableAutostart() : Promise<Result<null, string>> {
    try {
    return { status: "ok", data: await TAURI_INVOKE("disable_autostart") };
} catch (e) {
    if(e instanceof Error) throw e;
    else return { status: "error", error: e  as any };
}
},
/**
 * Check if autostart is enabled
 */
async isAutostartEnabled() : Promise<Result<boolean, string>> {
    try {
    return { status: "ok", data: await TAURI_INVOKE("is_autostart_enabled") };
} catch (e) {
    if(e instanceof Error) throw e;
    else return { status: "error", error: e  as any };
}
},
/**
 * Mark that initial autostart setup has been completed
 * This is called after enabling autostart on first launch
 */
async markAutostartSetupDone() : Promise<Result<null, string>> {
    try {
    return { status: "ok", data: await TAURI_INVOKE("mark_autostart_setup_done") };
} catch (e) {
    if(e instanceof Error) throw e;
    else return { status: "error", error: e  as any };
}
},
/**
 * Check if initial autostart setup has been completed
 */
async isAutostartSetupDone() : Promise<Result<boolean, string>> {
    try {
    return { status: "ok", data: await TAURI_INVOKE("is_autostart_setup_done") };
} catch (e) {
    if(e instanceof Error) throw e;
    else return { status: "error", error: e  as any };
}
}
}

/** user-defined events **/


export const events = __makeEvents__<{
keyCaptureEvent: KeyCaptureEvent,
modelDownloadStateChanged: ModelDownloadStateChanged,
modelLoadingStateChanged: ModelLoadingStateChanged,
recordingStateChanged: RecordingStateChanged
}>({
keyCaptureEvent: "key-capture-event",
modelDownloadStateChanged: "model-download-state-changed",
modelLoadingStateChanged: "model-loading-state-changed",
recordingStateChanged: "recording-state-changed"
})

/** user-defined constants **/



/** user-defined types **/

/**
 * App configuration (stored locally)
 */
export type AppConfig = { 
/**
 * Currently active provider (only one can be active)
 */
activeProvider: Provider | null; 
/**
 * Key used to trigger recording (default: Fn)
 */
recordingTrigger?: RecordingTrigger; 
/**
 * Whether autostart has been set up on first launch
 * This prevents re-enabling autostart after user manually disables it
 */
autostartInitialSetupDone?: boolean; 
/**
 * Whether to run LLM post-processing after transcription
 */
postProcessEnabled: boolean; 
/**
 * OpenAI model used for transcription post-processing
 */
postProcessModel: string; 
/**
 * Prompt used for transcription post-processing
 */
postProcessPrompt: string; 
/**
 * Minimum speech duration required before running transcription (milliseconds)
 */
minSpeechDurationMs: number }
/**
 * Frontend-facing status for Azure OpenAI provider (never exposes API key)
 */
export type AzureOpenAIConfigStatus = { configured: boolean; endpoint: string }
/**
 * Key capture event - streamed to frontend during shortcut configuration
 */
export type KeyCaptureEvent = 
/**
 * Key was pressed
 */
{ type: "keyDown"; keycode: number; label: string } | 
/**
 * Key was released
 */
{ type: "keyUp"; keycode: number; label: string }
/**
 * Local model provider configuration (stored in local store, not keychain)
 */
export type LocalModelConfig = { 
/**
 * Name of the selected model (e.g., "whisper-small")
 */
selectedModel: string | null }
/**
 * Model download state change event - single event stream for all download state transitions
 */
export type ModelDownloadStateChanged = 
/**
 * Download is in progress
 */
{ state: "progress"; modelName: string; downloadedBytes: number; totalBytes: number; percentage: number } | 
/**
 * Download complete, verifying checksum
 */
{ state: "verifying"; modelName: string } | 
/**
 * Download completed successfully
 */
{ state: "complete"; modelName: string } | 
/**
 * Download failed with an error
 */
{ state: "error"; modelName: string; error: string }
/**
 * Combined view sent to frontend (catalog + status merged).
 */
export type ModelInfo = { name: string; displayName: string; description: string; sizeBytes: number; estimatedRamMb: number; isDownloaded: boolean; isDownloading: boolean; isLoaded: boolean; isLoading: boolean; downloadedBytes: number }
/**
 * Model loading state change event - single event stream for all loading state transitions
 */
export type ModelLoadingStateChanged = 
/**
 * Model loading has started
 */
{ state: "started"; modelName: string } | 
/**
 * Model loaded successfully
 */
{ state: "complete"; modelName: string } | 
/**
 * Model loading failed with an error
 */
{ state: "error"; modelName: string; error: string }
/**
 * Onboarding configuration (stored locally)
 */
export type OnboardingConfig = { 
/**
 * Whether the user has completed or skipped onboarding
 */
finished: boolean; 
/**
 * Current step in the onboarding flow
 */
currentStep: OnboardingStep; 
/**
 * Flag to track if we're resuming after an accessibility restart
 */
pendingRestart: boolean }
/**
 * Onboarding step enum - tracks current position in the wizard
 */
export type OnboardingStep = "welcome" | "accessibility" | "microphone" | "api_keys" | "shortcuts" | "fn_hold" | "fn_space" | "complete"
/**
 * Frontend-facing status for OpenAI provider (never exposes API key)
 */
export type OpenAIConfigStatus = { configured: boolean }
/**
 * Provider types supported by the application
 */
export type Provider = "open_ai" | "azure_open_ai" | "local"
/**
 * Recording state change event - single event stream for all state transitions
 */
export type RecordingStateChanged = 
/**
 * Recording has started
 */
{ state: "started" } | 
/**
 * Recording is being transcribed
 */
{ state: "transcribing" } | 
/**
 * Recording completed successfully
 */
{ state: "stopped"; text: string } | 
/**
 * Recording was cancelled by user
 */
{ state: "cancelled" } | 
/**
 * An error occurred during recording or transcription
 */
{ state: "error"; errorType: string; errorMessage: string; userMessage: string; audioFilePath: string | null }
/**
 * Recording trigger key options
 */
export type RecordingTrigger = "fn" | "control" | "option" | "command"
/**
 * A keyboard shortcut (1-3 keys)
 */
export type Shortcut = { keys: ShortcutKey[] }
/**
 * A single key in a shortcut combination
 */
export type ShortcutKey = { keycode: number; label: string }
/**
 * Complete shortcuts configuration
 */
export type ShortcutsConfig = { 
/**
 * Push-to-talk: Hold to record, release to stop
 */
pushToRecord: Shortcut; 
/**
 * Hands-free: Press to toggle (start/stop)
 */
handsFree: Shortcut }

/** tauri-specta globals **/

import {
	invoke as TAURI_INVOKE,
	Channel as TAURI_CHANNEL,
} from "@tauri-apps/api/core";
import * as TAURI_API_EVENT from "@tauri-apps/api/event";
import { type WebviewWindow as __WebviewWindow__ } from "@tauri-apps/api/webviewWindow";

type __EventObj__<T> = {
	listen: (
		cb: TAURI_API_EVENT.EventCallback<T>,
	) => ReturnType<typeof TAURI_API_EVENT.listen<T>>;
	once: (
		cb: TAURI_API_EVENT.EventCallback<T>,
	) => ReturnType<typeof TAURI_API_EVENT.once<T>>;
	emit: null extends T
		? (payload?: T) => ReturnType<typeof TAURI_API_EVENT.emit>
		: (payload: T) => ReturnType<typeof TAURI_API_EVENT.emit>;
};

export type Result<T, E> =
	| { status: "ok"; data: T }
	| { status: "error"; error: E };

function __makeEvents__<T extends Record<string, any>>(
	mappings: Record<keyof T, string>,
) {
	return new Proxy(
		{} as unknown as {
			[K in keyof T]: __EventObj__<T[K]> & {
				(handle: __WebviewWindow__): __EventObj__<T[K]>;
			};
		},
		{
			get: (_, event) => {
				const name = mappings[event as keyof T];

				return new Proxy((() => {}) as any, {
					apply: (_, __, [window]: [__WebviewWindow__]) => ({
						listen: (arg: any) => window.listen(name, arg),
						once: (arg: any) => window.once(name, arg),
						emit: (arg: any) => window.emit(name, arg),
					}),
					get: (_, command: keyof __EventObj__<any>) => {
						switch (command) {
							case "listen":
								return (arg: any) => TAURI_API_EVENT.listen(name, arg);
							case "once":
								return (arg: any) => TAURI_API_EVENT.once(name, arg);
							case "emit":
								return (arg: any) => TAURI_API_EVENT.emit(name, arg);
						}
					},
				});
			},
		},
	);
}
